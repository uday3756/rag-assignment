# Option 1: OpenAI + free backup when quota exceeded
# OPENAI_API_KEY=sk-your-key-here
# Optional backups (tried in order when primary returns 429):
#   – GROQ_API_KEY=...   free at console.groq.com, used for chat fallback
#   – OPENAI_BACKUP_API_KEY=sk-second-key   second OpenAI key
# OPENAI_CHAT_MODEL=gpt-4o-mini
# OPENAI_EMBED_MODEL=text-embedding-3-small
# GROQ_CHAT_MODEL=llama-3.1-8b-instant   # only if using Groq

# Option 2: Ollama – free local LLM (no key, no quota)
# 1) Install Ollama: https://ollama.com/download
# 2) In a terminal run: ollama pull nomic-embed-text  &&  ollama pull llama3.2
# 3) Uncomment below and restart dev server
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_API_KEY=ollama
# OPENAI_CHAT_MODEL=llama3.2
# OPENAI_EMBED_MODEL=nomic-embed-text
